{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Model Research\n",
    "\n",
    "The scope of this notebook is to assess and train different sequence models given the training data generated.\n",
    "\n",
    "Training data is generated based on financial time series data labeled with potential profits using a buy-sell system.\n",
    "\n",
    "The goal is to create a sequence model that can choose favourable stock charts equal to or better than a human can via traditional technical analysis.\n",
    "\n",
    "## Import Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'Python' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# List available devices\n",
    "devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"GPUs available: \", devices)\n",
    "\n",
    "# Confirm TensorFlow is using the GPU\n",
    "if devices:\n",
    "    print(\"TensorFlow is using the GPU\")\n",
    "else:\n",
    "    print(\"TensorFlow is not using the GPU\")\n",
    "\n",
    "# Define the data directory relative to the script location\n",
    "data_dir = 'data'\n",
    "\n",
    "# Define the file paths\n",
    "sequences_path = os.path.join(data_dir, 'sequences.npy')\n",
    "labels_path = os.path.join(data_dir, 'labels.npy')\n",
    "metadata_path = os.path.join(data_dir, 'metadata.npy')\n",
    "\n",
    "# Load the data\n",
    "try:\n",
    "    data_sequences = np.load(sequences_path)\n",
    "    data_labels = np.load(labels_path)\n",
    "    data_metadata = np.load(metadata_path)\n",
    "\n",
    "    # Inspect the shape of the loaded data\n",
    "    print(f'Sequences shape: {data_sequences.shape}')\n",
    "    print(f'Labels shape: {data_labels.shape}')\n",
    "    print(f'Metadata shape: {data_metadata.shape}')\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading files: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'Python' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# Shuffle the data\n",
    "indices = np.arange(data_sequences.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "data_sequences = data_sequences[indices]\n",
    "data_labels = data_labels[indices]\n",
    "data_metadata = data_metadata[indices]\n",
    "\n",
    "# Define the threshold for considering a buy\n",
    "threshold = 0.1  # Example threshold value\n",
    "\n",
    "# Transform labels to binary (1 for buy, 0 for no buy)\n",
    "binary_labels = (data_labels >= threshold).astype(int)\n",
    "\n",
    "# Define the proportions for the splits\n",
    "train_size = 0.7  # 70%\n",
    "validation_size = 0.15  # 15%\n",
    "test_size = 0.15  # 15%\n",
    "\n",
    "# Calculate the number of samples for each set\n",
    "num_samples = data_sequences.shape[0]\n",
    "train_end = int(num_samples * train_size)\n",
    "validation_end = int(num_samples * (train_size + validation_size))\n",
    "\n",
    "# Split the data\n",
    "X_train = data_sequences[:train_end]\n",
    "y_train = binary_labels[:train_end]\n",
    "profits_train = data_labels[:train_end]\n",
    "\n",
    "X_val = data_sequences[train_end:validation_end]\n",
    "y_val = binary_labels[train_end:validation_end]\n",
    "profits_val = data_labels[train_end:validation_end]\n",
    "\n",
    "X_test = data_sequences[validation_end:]\n",
    "y_test = binary_labels[validation_end:]\n",
    "profits_test = data_labels[validation_end:]\n",
    "\n",
    "# Inspect the shape of the splits\n",
    "print(f'Training set shape: {X_train.shape}, {y_train.shape}')\n",
    "print(f'Validation set shape: {X_val.shape}, {y_val.shape}')\n",
    "print(f'Test set shape: {X_test.shape}, {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'Python' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer\n",
    "model.add(Input(shape=(X_train.shape[1], X_train.shape[2])))\n",
    "\n",
    "# First LSTM layer (return_sequences=True to pass sequences to the next LSTM layer)\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "\n",
    "# Second LSTM layer (final LSTM layer, return_sequences=False to pass a single vector)\n",
    "model.add(LSTM(50, return_sequences=False))\n",
    "\n",
    "# Dense layer with 25 units\n",
    "model.add(Dense(25))\n",
    "\n",
    "# Output layer with 1 unit for binary classification (sigmoid activation)\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model using the custom loss function\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'Python' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# Train the model with validation data\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=32, epochs=20)\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Predicting and evaluating the model\n",
    "train_predict = model.predict(X_train)\n",
    "val_predict = model.predict(X_val)\n",
    "test_predict = model.predict(X_test)\n",
    "\n",
    "# Convert probabilities to binary predictions\n",
    "train_predict = (train_predict > 0.5).astype(int)\n",
    "val_predict = (val_predict > 0.5).astype(int)\n",
    "test_predict = (test_predict > 0.5).astype(int)\n",
    "\n",
    "# Calculate accuracy\n",
    "train_accuracy = np.mean(train_predict == y_train)\n",
    "val_accuracy = np.mean(val_predict == y_val)\n",
    "test_accuracy = np.mean(test_predict == y_test)\n",
    "\n",
    "print(f'Train Accuracy: {train_accuracy * 100:.2f}%')\n",
    "print(f'Validation Accuracy: {val_accuracy * 100:.2f}%')\n",
    "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
