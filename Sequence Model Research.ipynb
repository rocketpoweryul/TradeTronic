{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Model Research\n",
    "\n",
    "The scope of this notebook is to assess and train different sequence models given the training data generated.\n",
    "\n",
    "Training data is generated based on financial time series data labeled with potential profits using a buy-sell system.\n",
    "\n",
    "The goal is to create a sequence model that can choose favourable stock charts equal to or better than a human can via traditional technical analysis.\n",
    "\n",
    "## Import Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sequences shape: (115000, 63, 19)\n",
      "Loaded sequences size: 137655000\n",
      "Loaded labels shape: (115000,)\n",
      "Loaded metadata shape: (115000, 2)\n",
      "Expected total size: 434700000\n",
      "\n",
      "Price-related columns:\n",
      "Index: 0, Column: Open\n",
      "Index: 1, Column: High\n",
      "Index: 2, Column: Low\n",
      "Index: 3, Column: Close\n",
      "Index: 9, Column: Close_21_bar_ema\n",
      "Index: 10, Column: Close_50_bar_sma\n",
      "Index: 11, Column: Close_150_bar_sma\n",
      "Index: 12, Column: Close_200_bar_sma\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Define the data directory relative to the script location\n",
    "data_dir = 'data'\n",
    "\n",
    "# Define the file paths\n",
    "sequences_path = os.path.join(data_dir, 'sequences.npy')\n",
    "labels_path = os.path.join(data_dir, 'labels.npy')\n",
    "metadata_path = os.path.join(data_dir, 'metadata.npy')\n",
    "\n",
    "# Load the data\n",
    "try:\n",
    "    data_sequences = np.load(sequences_path)\n",
    "    data_labels = np.load(labels_path)\n",
    "    data_metadata = np.load(metadata_path)\n",
    "\n",
    "    # Number of examples to select\n",
    "    num_examples = 115000\n",
    "\n",
    "    # Generate a random permutation of indices\n",
    "    indices = np.random.permutation(len(data_sequences))\n",
    "\n",
    "    # Select the first `num_examples` indices\n",
    "    selected_indices = indices[:num_examples]\n",
    "\n",
    "    # Use the selected indices to create the random subset\n",
    "    data_sequences = data_sequences[selected_indices, -84:, :]\n",
    "    data_labels = data_labels[selected_indices]\n",
    "    data_metadata = data_metadata[selected_indices]\n",
    "\n",
    "    # Inspect the shape and size of the loaded data before slicing\n",
    "    print(f'Loaded sequences shape: {data_sequences.shape}')\n",
    "    print(f'Loaded sequences size: {data_sequences.size}')\n",
    "    print(f'Loaded labels shape: {data_labels.shape}')\n",
    "    print(f'Loaded metadata shape: {data_metadata.shape}')\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading files: {e}\")\n",
    "except ValueError as e:\n",
    "    print(f\"Value error: {e}\")\n",
    "\n",
    "# Calculate and print the expected total size\n",
    "expected_total_size = num_examples * 252 * 15\n",
    "print(f'Expected total size: {expected_total_size}')\n",
    "\n",
    "# Define relevant columns and indices for normalization\n",
    "relevant_columns = [\n",
    "    'Open', 'High', 'Low', 'Close', 'Volume', 'Turnover', 'Consol_Detected',\n",
    "    'Consol_Len_Bars', 'Consol_Depth_Percent', 'Close_21_bar_ema',\n",
    "    'Close_50_bar_sma', 'Close_150_bar_sma', 'Close_200_bar_sma',\n",
    "    'RSL', 'RSL_NH', 'UpDownVolumeRatio', 'ATR', '%B'\n",
    "]\n",
    "\n",
    "price_columns_indices = [0, 1, 2, 3, 9, 10, 11, 12]  # Indices of price-related columns in the sequence data\n",
    "\n",
    "# Map indices to column names\n",
    "price_columns = [relevant_columns[i] for i in price_columns_indices]\n",
    "\n",
    "print(\"\\nPrice-related columns:\")\n",
    "for index, column in zip(price_columns_indices, price_columns):\n",
    "    print(f\"Index: {index}, Column: {column}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "### NaN Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in data_sequences: 1218686\n",
      "NaNs remaining in data_sequences after removal: 0\n",
      "NaNs in data_labels: 0\n",
      "Data Seq Min: 0.0\n",
      "Data Seq Max: 468223510183936.0\n"
     ]
    }
   ],
   "source": [
    "# Replace all NaNs with 0 due to moving averages having insufficient data to compute anything, leaving blank inputs.\n",
    "# Check if NaNs exist\n",
    "\n",
    "# Dictionary to map variable names to their corresponding data arrays\n",
    "data_dict = {\n",
    "    'data_sequences': data_sequences,\n",
    "    'data_labels': data_labels,\n",
    "}\n",
    "\n",
    "# Using a dictionary to iterate over variables\n",
    "for var_name, data in data_dict.items():\n",
    "    num_nans = np.sum(np.isnan(data))\n",
    "    print(f\"NaNs in {var_name}: {num_nans}\")\n",
    "\n",
    "    # Remove NaNs\n",
    "    if num_nans > 0:\n",
    "        data_dict[var_name][:] = np.nan_to_num(data)\n",
    "        num_nans = np.sum(np.isnan(data))\n",
    "        print(f\"NaNs remaining in {var_name} after removal: {num_nans}\")\n",
    "\n",
    "print(f\"Data Seq Min: {np.min(data_sequences[:,:,price_columns_indices])}\")\n",
    "print(f\"Data Seq Max: {np.max(data_sequences[:,:,price_columns_indices])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corrupted sequence removal\n",
    "\n",
    "99% of stocks I buy will be below 1000, with a few above 1000, although they are important.\n",
    "\n",
    "I also noticed quite a few training examples have weird price data, which I filter out below.\n",
    "\n",
    "I noticed with thresholds above 3e3, the max is the threshold, which is very suspect.\n",
    "\n",
    "The loss of training examples is insignificant, and the result is better normalization of the data and obviously no corrupted sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abnormal Sequence Count: 1001\n",
      "Indices of abnormal sequences: [52, 60, 435, 661, 701, 736, 749, 994, 1009, 1051, 1184, 1234, 1275, 1363, 1471, 1505, 1522, 1702, 1869, 1886, 2066, 2237, 2416, 2536, 2609, 2629, 2871, 2885, 3046, 3068, 3479, 3570, 3576, 3611, 3629, 3634, 3673, 3676, 3716, 4270, 4417, 4610, 4627, 4678, 5020, 5180, 5225, 5284, 5332, 5412, 5459, 5583, 5775, 5797, 5871, 5945, 6110, 6391, 6880, 6998, 7097, 7731, 7864, 8021, 8053, 8059, 8106, 8108, 8269, 8437, 8460, 8936, 8991, 9033, 9038, 9110, 9113, 9129, 9164, 9193, 9212, 9351, 9428, 9568, 9758, 9765, 9891, 9923, 9962, 9978, 10272, 10384, 10417, 10429, 10498, 10784, 10865, 10945, 11178, 11209, 11230, 11252, 11275, 11424, 11614, 11873, 11943, 11973, 12306, 12435, 12436, 12558, 12570, 12685, 12780, 12950, 13062, 13064, 13158, 13175, 13609, 13754, 13767, 13776, 13808, 13872, 13956, 13968, 13990, 14057, 14090, 14097, 14265, 14271, 14496, 14501, 14548, 14574, 14669, 14728, 14820, 14961, 15013, 15068, 15164, 15265, 15294, 15392, 15444, 15594, 15644, 16058, 16064, 16293, 16642, 16746, 16791, 16808, 16851, 16922, 16933, 16980, 17048, 17134, 17193, 17280, 17453, 17653, 18110, 18167, 18271, 18362, 18432, 18673, 18773, 18790, 19103, 19116, 19775, 19842, 19936, 19957, 20203, 20397, 21070, 21132, 21187, 21386, 21435, 21447, 21715, 21741, 21818, 21885, 22090, 22096, 22159, 22465, 22543, 22836, 22875, 23127, 23148, 23538, 23961, 24038, 24153, 24232, 24319, 24382, 24460, 24470, 24475, 24479, 24562, 24578, 24605, 24639, 24689, 25153, 25179, 25200, 25646, 25782, 25839, 26574, 26624, 27037, 27205, 27206, 27253, 27261, 27484, 27818, 27943, 28060, 28172, 28209, 28411, 28455, 28703, 28746, 29060, 29149, 29274, 29316, 29347, 29353, 29377, 29551, 29717, 29769, 29979, 30071, 30140, 30196, 30269, 30394, 30586, 30639, 31140, 31207, 31220, 31347, 31403, 31599, 31628, 31732, 31736, 31769, 31969, 32113, 32480, 32499, 32648, 32706, 33001, 33485, 33683, 33865, 34156, 34163, 34427, 34477, 34500, 34714, 34717, 35108, 35111, 35337, 35479, 35508, 35565, 35678, 35846, 35887, 36165, 36408, 36779, 36878, 36884, 36904, 36930, 36952, 37011, 37063, 37072, 37105, 37116, 37127, 37180, 37466, 37826, 37942, 38055, 38272, 38376, 38392, 38398, 38452, 38829, 39095, 39254, 39315, 39553, 39599, 39684, 39939, 40090, 40259, 40326, 40452, 40543, 40600, 40601, 40747, 41051, 41167, 41322, 41327, 41567, 41584, 41608, 41952, 42293, 42620, 42694, 42722, 42919, 43009, 43044, 43463, 43597, 43669, 43711, 43772, 43961, 43993, 44009, 44063, 44340, 44387, 44503, 44559, 44903, 45161, 45180, 45332, 45532, 45546, 45604, 45621, 45629, 45733, 45745, 45962, 46120, 46439, 46529, 46615, 46621, 46743, 46863, 46907, 47043, 47082, 47160, 47330, 47335, 47387, 47451, 47462, 47709, 47929, 47933, 47941, 48287, 48374, 48574, 48606, 48624, 48648, 48676, 48756, 48757, 48775, 49011, 49050, 49073, 49090, 49165, 49541, 49673, 49744, 49779, 49796, 49871, 50104, 50107, 50109, 50503, 50533, 50770, 50776, 50935, 51037, 51041, 51180, 51186, 51204, 51243, 51308, 51411, 51451, 51454, 51480, 51512, 51744, 51782, 51993, 52023, 52034, 52203, 52275, 52347, 52371, 52520, 52566, 52818, 52833, 53148, 53195, 53390, 53440, 53444, 53452, 53685, 53790, 53810, 53931, 54201, 54273, 54278, 54282, 54546, 54731, 54766, 54868, 54935, 54976, 55112, 55167, 55251, 55280, 55318, 55407, 55429, 55465, 55636, 55980, 56005, 56179, 56325, 56366, 56378, 56412, 56443, 56462, 56499, 56503, 56723, 56763, 56838, 57202, 57253, 57282, 57714, 58009, 58051, 58208, 58378, 58414, 58523, 58629, 58727, 58824, 58858, 59058, 59093, 59125, 59215, 59261, 59383, 59472, 59487, 59588, 59746, 59799, 59819, 60292, 60332, 60461, 60530, 60613, 60653, 60734, 60945, 61067, 61107, 61255, 61461, 61530, 61581, 61588, 61595, 61927, 61979, 62113, 62188, 62330, 62383, 62386, 62475, 62597, 62651, 62793, 62950, 62970, 63163, 63170, 63265, 63355, 63371, 63469, 63503, 63506, 63597, 63751, 63835, 63885, 64087, 64103, 64294, 64396, 64877, 65018, 65059, 65156, 65188, 65276, 65654, 65895, 66517, 66527, 66593, 66599, 66614, 66741, 66850, 66862, 66907, 66932, 66967, 66982, 67012, 67024, 67132, 67298, 67338, 67369, 67434, 67471, 67686, 67747, 67815, 67891, 67925, 67944, 67965, 67994, 68034, 68047, 68241, 68336, 68574, 68628, 68940, 69181, 69411, 69426, 69435, 69601, 69783, 69808, 69957, 70303, 70737, 71041, 71059, 71096, 71122, 71191, 71224, 71561, 71816, 71933, 71935, 71940, 72077, 72094, 72207, 72407, 72415, 72455, 72905, 73036, 73071, 73187, 73257, 73436, 73594, 73619, 73661, 73722, 73770, 74113, 74435, 74487, 74756, 74830, 74976, 75228, 75234, 75359, 75390, 75656, 75667, 75788, 75800, 75865, 75882, 75930, 75964, 76104, 76367, 76394, 76435, 76585, 76622, 76637, 76641, 77376, 77430, 77500, 77559, 77611, 77649, 77683, 77699, 77721, 77835, 77965, 78201, 78907, 79077, 79078, 79249, 79288, 79472, 79499, 79669, 79830, 79861, 80063, 80076, 80130, 80208, 80288, 80350, 80372, 80385, 80567, 80729, 80802, 80809, 80914, 81075, 81125, 81144, 81268, 81303, 81315, 81331, 81557, 81758, 81820, 81855, 81892, 82124, 82194, 82224, 82228, 82230, 82331, 82413, 82513, 82580, 82636, 82751, 82764, 82816, 82889, 82892, 83062, 83139, 83500, 83513, 83602, 83654, 83694, 83790, 83894, 83976, 84162, 84243, 84418, 84590, 84785, 84834, 85012, 85215, 85349, 85367, 85841, 86014, 86133, 86218, 86430, 86454, 86718, 86850, 86932, 86947, 86981, 87220, 87482, 87538, 87614, 87618, 88178, 88183, 88219, 88260, 88285, 88314, 88321, 88365, 88380, 88428, 88451, 88472, 88484, 88534, 88645, 88763, 88780, 88989, 89001, 89027, 89165, 89276, 89316, 89359, 89524, 89549, 89612, 90043, 90217, 90271, 90274, 90351, 90515, 90658, 91138, 91249, 91344, 91366, 91436, 91667, 91945, 92054, 92193, 92516, 92526, 92723, 92825, 93116, 93157, 93178, 93236, 93382, 93421, 93538, 93541, 93766, 94053, 94127, 94199, 94402, 94734, 94969, 94991, 95096, 95106, 95179, 95586, 95686, 95828, 95832, 95972, 96067, 96069, 96086, 96099, 96241, 96588, 96616, 96730, 96845, 96891, 97060, 97441, 98025, 98427, 98479, 98562, 98735, 98810, 98866, 99101, 99165, 99171, 99254, 99318, 99689, 99748, 99769, 100329, 100431, 100526, 100884, 100951, 100956, 101100, 101153, 101551, 101581, 101702, 101736, 101807, 101816, 101926, 102045, 102056, 102441, 102460, 102466, 102502, 102659, 102842, 102886, 103043, 103059, 103103, 103207, 103285, 103402, 103423, 103431, 103437, 103770, 103862, 104291, 104441, 104620, 104624, 104712, 104832, 104891, 104910, 104965, 105153, 105240, 105247, 105263, 105360, 105653, 105719, 106234, 106263, 106386, 106695, 106697, 106700, 106810, 106847, 106860, 106945, 107008, 107097, 107121, 107196, 107211, 107233, 107259, 107309, 107824, 108023, 108039, 108142, 108447, 108467, 108523, 109013, 109081, 109089, 109136, 109143, 109153, 109221, 109374, 109561, 109620, 109883, 109947, 110057, 110249, 110332, 110345, 110392, 110425, 110467, 110642, 110855, 110921, 110929, 110930, 110932, 110959, 110971, 111328, 111367, 111657, 111823, 111968, 112178, 112232, 112248, 112287, 112291, 112403, 112516, 112694, 112875, 112969, 112989, 112993, 113118, 113184, 113210, 113343, 113524, 113629, 113684, 113716, 113744, 113881, 114038, 114090, 114927, 114984]\n",
      "Filtered data_sequences shape: (113999, 63, 19)\n",
      "Filtered data_labels shape: (113999,)\n",
      "Data Seq Min: 0.0\n",
      "Data Seq Max: 2991.8827185058594\n"
     ]
    }
   ],
   "source": [
    "# Set the threshold for abnormal values based on domain knowledge\n",
    "threshold = 3.0e3\n",
    "\n",
    "# Detect all sequences with abnormally large price data\n",
    "abnormal_sequences = []\n",
    "\n",
    "# Iterate through each sequence to check for abnormal values\n",
    "for sequence_index in range(data_sequences.shape[0]):\n",
    "    # Extract price-related columns for the current sequence\n",
    "    price_data = data_sequences[sequence_index, :, price_columns_indices]\n",
    "    \n",
    "    # Check if any value in the price_data exceeds the threshold\n",
    "    if np.any(price_data > threshold):\n",
    "        abnormal_sequences.append(sequence_index)\n",
    "\n",
    "# Print the indices of the abnormal sequences\n",
    "print(f\"Abnormal Sequence Count: {len(abnormal_sequences)}\")\n",
    "print(f\"Indices of abnormal sequences: {abnormal_sequences}\")\n",
    "\n",
    "# Create a mask for sequences that are not abnormal\n",
    "mask = np.ones(data_sequences.shape[0], dtype=bool)\n",
    "mask[abnormal_sequences] = False\n",
    "\n",
    "# Filter out abnormal sequences from data_sequences and data_labels\n",
    "filtered_data_sequences = data_sequences[mask]\n",
    "filtered_data_labels = data_labels[mask]\n",
    "\n",
    "# Print the shape of the filtered data\n",
    "print(f\"Filtered data_sequences shape: {filtered_data_sequences.shape}\")\n",
    "print(f\"Filtered data_labels shape: {filtered_data_labels.shape}\")\n",
    "\n",
    "print(f\"Data Seq Min: {np.min(filtered_data_sequences[:,:,price_columns_indices])}\")\n",
    "print(f\"Data Seq Max: {np.max(filtered_data_sequences[:,:,price_columns_indices])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization of Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Data Seq Min: -1000.0\n",
      "Normalized Data Seq Max: 1000.0\n",
      "Data Labels for > 10.0% Min: 0\n",
      "Data Labels for > 10.0% Max: 1\n",
      "Number of labels that are 1: 21255\n",
      "Number of labels that are 0: 93745\n",
      "Probability of randomly selecting a stock making 10.0% is 18.482608695652175%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Indices of price-related columns\n",
    "price_columns_indices = [0, 1, 2, 3]\n",
    "ma_columns_indices = [9, 10, 11, 12]\n",
    "\n",
    "# Extract data shapes\n",
    "num_sequences, num_timesteps, num_features = data_sequences.shape\n",
    "\n",
    "# Calculate log transformation for price-related features\n",
    "price_data = data_sequences[:, :, price_columns_indices]\n",
    "log_price_data = np.log(price_data + 1e-8)\n",
    "\n",
    "# Replace the original price-related features with the log values\n",
    "data_sequences[:, :, price_columns_indices] = log_price_data\n",
    "\n",
    "# Calculate percentage away from the Close price for moving averages\n",
    "close_price_data = data_sequences[:, :, 3].reshape(num_sequences, num_timesteps, 1)  # Close price at index 3\n",
    "ma_data = data_sequences[:, :, ma_columns_indices]\n",
    "\n",
    "# Avoid division by zero by adding epsilon\n",
    "epsilon = 1e-8\n",
    "percentage_away_from_close = (close_price_data - ma_data) / (ma_data + epsilon)\n",
    "\n",
    "# Replace the original moving average features with the percentage away values\n",
    "data_sequences[:, :, ma_columns_indices] = percentage_away_from_close\n",
    "\n",
    "# Handle infinite values by replacing them with NaNs and then replacing NaNs with zero\n",
    "data_sequences = np.nan_to_num(data_sequences, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "# Clip extreme values to avoid large outliers\n",
    "data_sequences = np.clip(data_sequences, -1e3, 1e3)\n",
    "\n",
    "# Normalize the price-related features together\n",
    "price_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "# Reshape the price-related features to fit the scaler\n",
    "original_shape = data_sequences[:, :, price_columns_indices].shape\n",
    "reshaped_data = data_sequences[:, :, price_columns_indices].reshape(-1, len(price_columns_indices))\n",
    "\n",
    "# Fit and transform the price-related features\n",
    "normalized_price_data = price_scaler.fit_transform(reshaped_data)\n",
    "\n",
    "# Reshape back to the original shape\n",
    "normalized_price_data = normalized_price_data.reshape(original_shape)\n",
    "\n",
    "# Replace the original price-related features with the normalized ones\n",
    "data_sequences[:, :, price_columns_indices] = normalized_price_data\n",
    "\n",
    "# Normalize the remaining features individually\n",
    "for feature_index in range(num_features):\n",
    "    if feature_index not in price_columns_indices and feature_index not in ma_columns_indices:\n",
    "        # Initialize a new scaler for each feature\n",
    "        feature_scaler = MinMaxScaler()\n",
    "\n",
    "        # Extract the feature data\n",
    "        feature_data = data_sequences[:, :, feature_index].reshape(-1, 1)\n",
    "\n",
    "        # Fit and transform the scaler\n",
    "        normalized_feature_data = feature_scaler.fit_transform(feature_data)\n",
    "\n",
    "        # Reshape back to the original shape\n",
    "        normalized_feature_data = normalized_feature_data.reshape(num_sequences, num_timesteps)\n",
    "\n",
    "        # Replace the original feature with the normalized one\n",
    "        data_sequences[:, :, feature_index] = normalized_feature_data\n",
    "\n",
    "# Print normalized data sequences to check\n",
    "print(f\"Normalized Data Seq Min: {np.min(data_sequences)}\")\n",
    "print(f\"Normalized Data Seq Max: {np.max(data_sequences)}\")\n",
    "\n",
    "# Make the labels a binary decision, rather than a profit\n",
    "min_profit = 0.1  # implies a good decision is a breakout that produces more than min_profit (*100 for percent, 0.2 = 20%)\n",
    "\n",
    "data_labels = (data_labels > min_profit).astype(int)\n",
    "\n",
    "print(f\"Data Labels for > {min_profit*100}% Min: {np.min(data_labels)}\")\n",
    "print(f\"Data Labels for > {min_profit*100}% Max: {np.max(data_labels)}\")\n",
    "\n",
    "# Count how many labels are 1 and how many are 0\n",
    "num_ones = np.sum(data_labels)\n",
    "num_zeros = len(data_labels) - num_ones\n",
    "\n",
    "print(f\"Number of labels that are 1: {num_ones}\")\n",
    "print(f\"Number of labels that are 0: {num_zeros}\")\n",
    "print(f\"Probability of randomly selecting a stock making {min_profit*100}% is {num_ones/(num_ones+num_zeros)*100}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model -> Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (115000, 63, 19)\n",
      "y shape: (115000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-23 06:04:08.864601: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-23 06:04:09.127329: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-23 06:04:09.127472: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-23 06:04:09.132434: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-23 06:04:09.132520: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-23 06:04:09.132566: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-23 06:04:09.338457: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-23 06:04:09.339147: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-23 06:04:09.339166: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-23 06:04:09.339240: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-23 06:04:09.339261: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5564 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "224               |224               |lstm_1_units\n",
      "0.001             |0.001             |l1_1\n",
      "1e-05             |1e-05             |l2_1\n",
      "0.3               |0.3               |dropout_1\n",
      "16                |16                |lstm_2_units\n",
      "0.001             |0.001             |l1_2\n",
      "0.0001            |0.0001            |l2_2\n",
      "0.3               |0.3               |dropout_2\n",
      "2                 |2                 |num_dense_layers\n",
      "24                |24                |dense_0_units\n",
      "1e-05             |1e-05             |l1_dense_0\n",
      "1e-05             |1e-05             |l2_dense_0\n",
      "0                 |0                 |dropout_dense_0\n",
      "0.0016953         |0.0016953         |learning_rate\n",
      "2                 |2                 |tuner/epochs\n",
      "0                 |0                 |tuner/initial_epoch\n",
      "4                 |4                 |tuner/bracket\n",
      "0                 |0                 |tuner/round\n",
      "\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-23 06:04:13.687016: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2024-06-23 06:04:14.485476: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f3111de34a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-23 06:04:14.485519: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3070 Ti Laptop GPU, Compute Capability 8.6\n",
      "2024-06-23 06:04:14.517881: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1719115454.637240  349919 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 391/4688 [=>............................] - ETA: 1:04 - loss: 1.0259 - accuracy: 0.4971 - precision: 0.4972 - recall: 0.9944"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 84\u001b[0m\n\u001b[1;32m     74\u001b[0m tuner \u001b[38;5;241m=\u001b[39m kt\u001b[38;5;241m.\u001b[39mHyperband(\n\u001b[1;32m     75\u001b[0m     build_model,\n\u001b[1;32m     76\u001b[0m     objective\u001b[38;5;241m=\u001b[39mkt\u001b[38;5;241m.\u001b[39mObjective(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_precision\u001b[39m\u001b[38;5;124m'\u001b[39m, direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     80\u001b[0m     project_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstock_prediction\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     81\u001b[0m )\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# Perform the search\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_resampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_resampled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m             \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m             \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m             \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# Get the best model\u001b[39;00m\n\u001b[1;32m     90\u001b[0m best_model \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mget_best_models(num_models\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/TradeTronic/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py:234\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_end(trial)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[0;32m~/anaconda3/envs/TradeTronic/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py:274\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m         trial\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m trial_module\u001b[38;5;241m.\u001b[39mTrialStatus\u001b[38;5;241m.\u001b[39mCOMPLETED\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/TradeTronic/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py:239\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[0;32m--> 239\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_trial(trial\u001b[38;5;241m.\u001b[39mtrial_id)\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mexists(\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    242\u001b[0m     ):\n\u001b[1;32m    243\u001b[0m         \u001b[38;5;66;03m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;66;03m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;66;03m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[1;32m    246\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe use case of calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    248\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    254\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    255\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/TradeTronic/lib/python3.11/site-packages/keras_tuner/src/tuners/hyperband.py:427\u001b[0m, in \u001b[0;36mHyperband.run_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    425\u001b[0m     fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m hp\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtuner/epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    426\u001b[0m     fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m hp\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtuner/initial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/TradeTronic/lib/python3.11/site-packages/keras_tuner/src/engine/tuner.py:314\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    313\u001b[0m     copied_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[0;32m--> 314\u001b[0m     obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_and_fit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcopied_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m     histories\u001b[38;5;241m.\u001b[39mappend(obj_value)\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "File \u001b[0;32m~/anaconda3/envs/TradeTronic/lib/python3.11/site-packages/keras_tuner/src/engine/tuner.py:233\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m hp \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39mhyperparameters\n\u001b[1;32m    232\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_build(hp)\n\u001b[0;32m--> 233\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# Save the build config for model loading later.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmulti_backend():\n",
      "File \u001b[0;32m~/anaconda3/envs/TradeTronic/lib/python3.11/site-packages/keras_tuner/src/engine/hypermodel.py:149\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    126\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/TradeTronic/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/TradeTronic/lib/python3.11/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/TradeTronic/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/TradeTronic/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/TradeTronic/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/TradeTronic/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/TradeTronic/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/TradeTronic/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/TradeTronic/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/TradeTronic/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/envs/TradeTronic/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from sklearn.utils import class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "import kerastuner as kt\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "\n",
    "# Print shapes to verify data\n",
    "print(f\"X shape: {data_sequences.shape}\")\n",
    "print(f\"y shape: {data_labels.shape}\")\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_sequences, data_labels, test_size=0.2, random_state=42, stratify=data_labels)\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = dict(enumerate(class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)))\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_reshaped = X_train.reshape(X_train.shape[0], -1)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_reshaped, y_train)\n",
    "X_train_resampled = X_train_resampled.reshape(X_train_resampled.shape[0], X_train.shape[1], X_train.shape[2])\n",
    "\n",
    "# Get the number of features and sequence length\n",
    "n_features = data_sequences.shape[2]\n",
    "sequence_length = data_sequences.shape[1]\n",
    "\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # First LSTM layer\n",
    "    model.add(LSTM(\n",
    "        units=hp.Int('lstm_1_units', min_value=32, max_value=256, step=32),\n",
    "        return_sequences=True,\n",
    "        input_shape=(sequence_length, n_features),\n",
    "        kernel_regularizer=l1_l2(l1=hp.Choice('l1_1', [1e-5, 1e-4, 1e-3]), l2=hp.Choice('l2_1', [1e-5, 1e-4, 1e-3]))\n",
    "    ))\n",
    "    model.add(Dropout(hp.Float('dropout_1', min_value=0.0, max_value=0.5, step=0.1)))\n",
    "    \n",
    "    # Second LSTM layer\n",
    "    model.add(LSTM(\n",
    "        units=hp.Int('lstm_2_units', min_value=16, max_value=128, step=16),\n",
    "        kernel_regularizer=l1_l2(l1=hp.Choice('l1_2', [1e-5, 1e-4, 1e-3]), l2=hp.Choice('l2_2', [1e-5, 1e-4, 1e-3]))\n",
    "    ))\n",
    "    model.add(Dropout(hp.Float('dropout_2', min_value=0.0, max_value=0.5, step=0.1)))\n",
    "    \n",
    "    # Dense layers\n",
    "    for i in range(hp.Int('num_dense_layers', 1, 3)):\n",
    "        model.add(Dense(\n",
    "            units=hp.Int(f'dense_{i}_units', min_value=8, max_value=64, step=8),\n",
    "            activation='relu',\n",
    "            kernel_regularizer=l1_l2(l1=hp.Choice(f'l1_dense_{i}', [1e-5, 1e-4, 1e-3]), l2=hp.Choice(f'l2_dense_{i}', [1e-5, 1e-4, 1e-3]))\n",
    "        ))\n",
    "        model.add(Dropout(hp.Float(f'dropout_dense_{i}', min_value=0.0, max_value=0.5, step=0.1)))\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=Adam(hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', Precision(), Recall()]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Initialize the tuner\n",
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective=kt.Objective('val_precision', direction='max'),\n",
    "    max_epochs=100,\n",
    "    factor=3,\n",
    "    directory='keras_tuner',\n",
    "    project_name='stock_prediction'\n",
    ")\n",
    "\n",
    "# Perform the search\n",
    "tuner.search(X_train_resampled, y_train_resampled,\n",
    "             epochs=100,\n",
    "             validation_data=(X_test, y_test),\n",
    "             class_weight=class_weights)\n",
    "\n",
    "# Get the best model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Evaluate the best model\n",
    "test_loss, test_accuracy, test_precision, test_recall = best_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Precision: {test_precision:.4f}\")\n",
    "print(f\"Test Recall: {test_recall:.4f}\")\n",
    "\n",
    "# Make predictions\n",
    "predictions = best_model.predict(X_test)\n",
    "predicted_classes = (predictions > 0.5).astype(int).flatten()\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test, predicted_classes)\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, predicted_classes))\n",
    "\n",
    "# Calculate the percentage of positive predictions\n",
    "positive_predictions_percentage = (predicted_classes.sum() / len(predicted_classes)) * 100\n",
    "print(f\"\\nPercentage of positive predictions: {positive_predictions_percentage:.2f}%\")\n",
    "\n",
    "# Print the best hyperparameters\n",
    "best_hp = tuner.get_best_hyperparameters(1)[0]\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "for param, value in best_hp.values.items():\n",
    "    print(f\"{param}: {value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
