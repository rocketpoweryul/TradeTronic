{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Model Research\n",
    "\n",
    "The scope of this notebook is to assess and train different sequence models given the training data generated.\n",
    "\n",
    "Training data is generated based on financial time series data labeled with potential profits using a buy-sell system.\n",
    "\n",
    "The goal is to create a sequence model that can choose favourable stock charts equal to or better than a human can via traditional technical analysis.\n",
    "\n",
    "# Import Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Define the data directory relative to the script location\n",
    "data_dir = 'data'\n",
    "\n",
    "# Define the file paths\n",
    "sequences_path = os.path.join(data_dir, 'sequences.npy')\n",
    "labels_path = os.path.join(data_dir, 'labels.npy')\n",
    "metadata_path = os.path.join(data_dir, 'metadata.npy')\n",
    "\n",
    "# Load feature column names\n",
    "with open('data/feature_columns.json', 'r') as f:\n",
    "    feature_columns = json.load(f)\n",
    "print(feature_columns)\n",
    "\n",
    "# Load the data\n",
    "try:\n",
    "    data_sequences = np.load(sequences_path)\n",
    "    data_labels = np.load(labels_path)\n",
    "    data_metadata = np.load(metadata_path)\n",
    "\n",
    "    # Number of examples to select\n",
    "    num_examples = 115000\n",
    "\n",
    "    # Generate a random permutation of indices\n",
    "    indices = np.random.permutation(len(data_sequences))\n",
    "\n",
    "    # Select the first `num_examples` indices\n",
    "    #selected_indices = indices[:num_examples]\n",
    "    selected_indices = indices\n",
    "\n",
    "    # Use the selected indices to create the random subset\n",
    "    data_sequences = data_sequences[selected_indices, :, :]\n",
    "    data_labels = data_labels[selected_indices]\n",
    "    data_metadata = data_metadata[selected_indices]\n",
    "\n",
    "    # Inspect the shape and size of the loaded data before slicing\n",
    "    print(f'Loaded sequences shape: {data_sequences.shape}')\n",
    "    print(f'Loaded sequences size: {data_sequences.size}')\n",
    "    print(f'Loaded labels shape: {data_labels.shape}')\n",
    "    print(f'Loaded metadata shape: {data_metadata.shape}')\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading files: {e}\")\n",
    "except ValueError as e:\n",
    "    print(f\"Value error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "### NaN anf INF Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Dictionary to map variable names to their corresponding data arrays\n",
    "data_dict = {\n",
    "    'data_sequences': data_sequences,\n",
    "    'data_labels': data_labels,\n",
    "}\n",
    "\n",
    "# Using a dictionary to iterate over variables\n",
    "for var_name, data in data_dict.items():\n",
    "    num_nans = np.sum(np.isnan(data))\n",
    "    num_infs = np.sum(np.isinf(data))\n",
    "    print(f\"NaNs in {var_name}: {num_nans}\")\n",
    "    print(f\"Infs in {var_name}: {num_infs}\")\n",
    "\n",
    "    # Remove NaNs and Infs\n",
    "    if num_nans > 0 or num_infs > 0:\n",
    "        data_dict[var_name][:] = np.nan_to_num(data, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        num_nans_after = np.sum(np.isnan(data))\n",
    "        num_infs_after = np.sum(np.isinf(data))\n",
    "        print(f\"NaNs remaining in {var_name} after removal: {num_nans_after}\")\n",
    "        print(f\"Infs remaining in {var_name} after removal: {num_infs_after}\")\n",
    "\n",
    "print(\"NaN and Inf removal completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corrupted sequence removal\n",
    "\n",
    "99% of stocks I buy will be below 1000, with a few above 1000, although they are important.\n",
    "\n",
    "I also noticed quite a few training examples have weird price data, which I filter out below.\n",
    "\n",
    "I noticed with thresholds above 3e3, the max is the threshold, which is very suspect.\n",
    "\n",
    "The loss of training examples is insignificant, and the result is better normalization of the data and obviously no corrupted sequences.\n",
    "\n",
    "#### Feature Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def print_feature_stats(data_sequences, feature_columns):\n",
    "    print(\"Feature Statistics:\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    for i, feature_name in enumerate(feature_columns):\n",
    "        feature_data = data_sequences[:, :, i].flatten()\n",
    "        \n",
    "        stats = {\n",
    "            \"Mean\": np.mean(feature_data),\n",
    "            \"Median\": np.median(feature_data),\n",
    "            \"Std Dev\": np.std(feature_data),\n",
    "            \"Min\": np.min(feature_data),\n",
    "            \"Max\": np.max(feature_data),\n",
    "            \"25th Percentile\": np.percentile(feature_data, 25),\n",
    "            \"75th Percentile\": np.percentile(feature_data, 75),\n",
    "            \"Skewness\": pd.Series(feature_data).skew(),\n",
    "            \"Kurtosis\": pd.Series(feature_data).kurtosis(),\n",
    "            \"Zero Count\": np.sum(feature_data == 0),\n",
    "            \"Zero Percentage\": np.mean(feature_data == 0) * 100\n",
    "        }\n",
    "        \n",
    "        print(f\"Feature: {feature_name}\")\n",
    "        for stat_name, stat_value in stats.items():\n",
    "            print(f\"  {stat_name}: {stat_value:.4f}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Call the function to print statistics\n",
    "print_feature_stats(data_sequences, feature_columns)\n",
    "\n",
    "# Additional overall statistics\n",
    "print(\"Overall Dataset Statistics:\")\n",
    "print(f\"Total number of sequences: {data_sequences.shape[0]}\")\n",
    "print(f\"Sequence length: {data_sequences.shape[1]}\")\n",
    "print(f\"Number of features: {data_sequences.shape[2]}\")\n",
    "print(f\"Total number of data points: {data_sequences.size}\")\n",
    "print(f\"Memory usage: {data_sequences.nbytes / (1024 * 1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization of Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Assuming feature_columns is defined somewhere in your code\n",
    "feature_indices = {name: idx for idx, name in enumerate(feature_columns)}\n",
    "\n",
    "# Function to remove outliers and cap values\n",
    "def preprocess_data(sequences, labels):\n",
    "    # Reshape sequences to 2D array for easier processing (flatten the timesteps)\n",
    "    num_sequences, num_timesteps, num_features = sequences.shape\n",
    "    sequences_reshaped = sequences.reshape(-1, num_features)\n",
    "    \n",
    "    # Create a mask to filter out invalid sequences\n",
    "    valid_mask = (\n",
    "        (sequences_reshaped[:, feature_indices['Distance_to_21EMA']] <= 100) &\n",
    "        (sequences_reshaped[:, feature_indices['Distance_to_50SMA']] <= 200) &\n",
    "        (sequences_reshaped[:, feature_indices['Distance_to_200SMA']] <= 500)\n",
    "    )\n",
    "    \n",
    "    # Reshape the valid_mask to match the original sequence shape\n",
    "    valid_mask_reshaped = valid_mask.reshape(num_sequences, num_timesteps)\n",
    "    \n",
    "    # Filter out sequences with any invalid timesteps\n",
    "    valid_sequences_mask = valid_mask_reshaped.all(axis=1)\n",
    "    filtered_sequences = sequences[valid_sequences_mask]\n",
    "    filtered_labels = labels[valid_sequences_mask]\n",
    "    \n",
    "    # Cap 'UpDownVolumeRatio' at 10\n",
    "    filtered_sequences[:, :, feature_indices['UpDownVolumeRatio']] = np.minimum(\n",
    "        filtered_sequences[:, :, feature_indices['UpDownVolumeRatio']], 10\n",
    "    )\n",
    "    \n",
    "    # Normalize the features using Z-score normalization followed by Min-Max normalization\n",
    "    for i in range(num_features):\n",
    "        # Apply Z-score normalization\n",
    "        feature_data = filtered_sequences[:, :, i].reshape(-1, 1)\n",
    "        scaler = StandardScaler()\n",
    "        scaled_data = scaler.fit_transform(feature_data)\n",
    "        \n",
    "        # Apply Min-Max normalization\n",
    "        min_max_scaler = MinMaxScaler()\n",
    "        normalized_data = min_max_scaler.fit_transform(scaled_data)\n",
    "        \n",
    "        # Reshape back to the original sequence shape\n",
    "        filtered_sequences[:, :, i] = normalized_data.reshape(filtered_sequences.shape[0], filtered_sequences.shape[1])\n",
    "    \n",
    "    return filtered_sequences, filtered_labels\n",
    "\n",
    "# Function to print feature statistics\n",
    "def print_feature_stats(data_sequences, feature_columns):\n",
    "    print(\"Feature Statistics:\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    for i, feature_name in enumerate(feature_columns):\n",
    "        feature_data = data_sequences[:, :, i].flatten()\n",
    "        \n",
    "        stats = {\n",
    "            \"Mean\": np.mean(feature_data),\n",
    "            \"Median\": np.median(feature_data),\n",
    "            \"Std Dev\": np.std(feature_data),\n",
    "            \"Min\": np.min(feature_data),\n",
    "            \"Max\": np.max(feature_data),\n",
    "            \"25th Percentile\": np.percentile(feature_data, 25),\n",
    "            \"75th Percentile\": np.percentile(feature_data, 75),\n",
    "            \"Skewness\": pd.Series(feature_data).skew(),\n",
    "            \"Kurtosis\": pd.Series(feature_data).kurtosis(),\n",
    "            \"Zero Count\": np.sum(feature_data == 0),\n",
    "            \"Zero Percentage\": np.mean(feature_data == 0) * 100\n",
    "        }\n",
    "        \n",
    "        print(f\"Feature: {feature_name}\")\n",
    "        for stat_name, stat_value in stats.items():\n",
    "            print(f\"  {stat_name}: {stat_value:.4f}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Example usage with data_sequences and data_labels\n",
    "# Assuming data_sequences is loaded and has shape (115000, 63, 12)\n",
    "\n",
    "# Process the data\n",
    "normalized_data, processed_labels = preprocess_data(data_sequences, data_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stats again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print statistics\n",
    "print_feature_stats(normalized_data, feature_columns)\n",
    "\n",
    "# Additional overall statistics\n",
    "print(\"Overall Dataset Statistics:\")\n",
    "print(f\"Total number of sequences: {normalized_data.shape[0]}\")\n",
    "print(f\"Sequence length: {normalized_data.shape[1]}\")\n",
    "print(f\"Number of features: {normalized_data.shape[2]}\")\n",
    "print(f\"Total number of data points: {normalized_data.size}\")\n",
    "print(f\"Memory usage: {normalized_data.nbytes / (1024 * 1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HP Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "import seaborn as sns\n",
    "import copy\n",
    "import time\n",
    "import optuna\n",
    "import json\n",
    "import logging\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Check for CUDA availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info(f\"Using device: {device}\")\n",
    "\n",
    "# Assuming normalized_data and processed_labels are defined\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    normalized_data, processed_labels, test_size=0.2, random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "y_train_tensor = torch.FloatTensor(y_train).to(device)\n",
    "X_test_tensor = torch.FloatTensor(X_test).to(device)\n",
    "y_test_tensor = torch.FloatTensor(y_test).to(device)\n",
    "\n",
    "# Define the model architecture (updated)\n",
    "class StockAnalysisModel(nn.Module):\n",
    "    def __init__(self, input_size, lstm_layers, linear_layers, dropout_rate_lstm, dropout_rate_linear, skip_connections):\n",
    "        super(StockAnalysisModel, self).__init__()\n",
    "        self.lstm_layers = nn.ModuleList()\n",
    "        self.linear_layers = nn.ModuleList()\n",
    "        self.skip_connections = skip_connections\n",
    "        \n",
    "        # LSTM layers\n",
    "        lstm_sizes = [int(size) for size in lstm_layers.split(',')]\n",
    "        for i, lstm_size in enumerate(lstm_sizes):\n",
    "            if i == 0:\n",
    "                self.lstm_layers.append(nn.LSTM(input_size, lstm_size, batch_first=True))\n",
    "            else:\n",
    "                self.lstm_layers.append(nn.LSTM(lstm_sizes[i-1], lstm_size, batch_first=True))\n",
    "        \n",
    "        # Linear layers\n",
    "        linear_sizes = [int(size) for size in linear_layers.split(',')]\n",
    "        input_size = lstm_sizes[-1]  # Use the last LSTM layer's output size as input to the first linear layer\n",
    "        for i, linear_size in enumerate(linear_sizes):\n",
    "            self.linear_layers.append(nn.Linear(input_size, linear_size))\n",
    "            input_size = linear_size  # Update input_size for the next layer\n",
    "        \n",
    "        self.final_layer = nn.Linear(linear_sizes[-1], 1)\n",
    "        self.dropout_lstm = nn.Dropout(dropout_rate_lstm)\n",
    "        self.dropout_linear = nn.Dropout(dropout_rate_linear)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Flatten parameters for all LSTM layers\n",
    "        for lstm in self.lstm_layers:\n",
    "            lstm.flatten_parameters()\n",
    "\n",
    "        # LSTM layers\n",
    "        lstm_out = x\n",
    "        for lstm_layer in self.lstm_layers:\n",
    "            lstm_out, _ = lstm_layer(lstm_out)\n",
    "            lstm_out = self.dropout_lstm(lstm_out)\n",
    "        \n",
    "        # Take the last output of the LSTM\n",
    "        linear_out = lstm_out[:, -1, :]\n",
    "        \n",
    "        # Linear layers\n",
    "        for i, linear_layer in enumerate(self.linear_layers):\n",
    "            new_linear_out = F.relu(linear_layer(linear_out))\n",
    "            if self.skip_connections and i > 0 and new_linear_out.shape == linear_out.shape:\n",
    "                linear_out = new_linear_out + linear_out\n",
    "            else:\n",
    "                linear_out = new_linear_out\n",
    "            linear_out = self.dropout_linear(linear_out)\n",
    "        \n",
    "        # Final layer\n",
    "        output = torch.sigmoid(self.final_layer(linear_out))\n",
    "        return output.squeeze()\n",
    "\n",
    "def save_checkpoint(epoch, model, optimizer, best_f1, params, checkpoint_path):\n",
    "    state = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'best_f1': best_f1,\n",
    "        'params': params\n",
    "    }\n",
    "    torch.save(state, checkpoint_path)\n",
    "\n",
    "def load_checkpoint(checkpoint_path, model, optimizer):\n",
    "    state = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(state['model_state_dict'])\n",
    "    optimizer.load_state_dict(state['optimizer_state_dict'])\n",
    "    return state['epoch'], state['best_f1'], state['params']\n",
    "\n",
    "def objective(trial):\n",
    "    try:\n",
    "        # Hyperparameter search space\n",
    "        params = {\n",
    "            'PROFIT_THRESH': trial.suggest_float('PROFIT_THRESH', 0.0, 0.1),\n",
    "            'LEARNING_RATE': trial.suggest_float('LEARNING_RATE', 1e-5, 1e-2, log=True),\n",
    "            'DROPOUT_RATE_LSTM': trial.suggest_float('DROPOUT_RATE_LSTM', 0.1, 0.5),\n",
    "            'DROPOUT_RATE_LINEAR': trial.suggest_float('DROPOUT_RATE_LINEAR', 0.1, 0.5),\n",
    "            'L2_REGULARIZATION': trial.suggest_float('L2_REGULARIZATION', 1e-6, 1e-3, log=True),\n",
    "            'PREDICTION_THRESHOLD': trial.suggest_float('PREDICTION_THRESHOLD', 0.1, 0.9),\n",
    "            'LSTM_LAYERS': trial.suggest_categorical('LSTM_LAYERS', ['64', '128', '64,32', '128,64', '128,64,32']),\n",
    "            'LINEAR_LAYERS': trial.suggest_categorical('LINEAR_LAYERS', ['32', '64', '32,16', '64,32', '64,32,16']),\n",
    "            'BATCH_SIZE': trial.suggest_categorical('BATCH_SIZE', [32, 64, 128, 256]),\n",
    "            'SKIP_CONNECTIONS': trial.suggest_categorical('SKIP_CONNECTIONS', [False, True])\n",
    "        }\n",
    "\n",
    "        # Set up MLflow\n",
    "        mlflow.set_experiment(\"Stock Analysis Model Tuning 2\")\n",
    "        with mlflow.start_run():\n",
    "            # Log hyperparameters\n",
    "            mlflow.log_params(params)\n",
    "\n",
    "            # Prepare data\n",
    "            y_train_binary = (y_train > params['PROFIT_THRESH']).astype(int)\n",
    "            y_test_binary = (y_test > params['PROFIT_THRESH']).astype(int)\n",
    "\n",
    "            # Log class distribution\n",
    "            train_class_distribution = np.bincount(y_train_binary)\n",
    "            test_class_distribution = np.bincount(y_test_binary)\n",
    "            logger.info(f\"Train class distribution: {train_class_distribution}\")\n",
    "            logger.info(f\"Test class distribution: {test_class_distribution}\")\n",
    "            train_positive_class_percentage = train_class_distribution[1] / len(y_train_binary) * 100\n",
    "            test_positive_class_percentage = test_class_distribution[1] / len(y_test_binary) * 100\n",
    "            mlflow.log_metric(\"train_positive_class_percentage\", train_positive_class_percentage)\n",
    "            mlflow.log_metric(\"test_positive_class_percentage\", test_positive_class_percentage)\n",
    "            logger.info(f\"Train positive class percentage: {train_positive_class_percentage:.2f}%\")\n",
    "            logger.info(f\"Test positive class percentage: {test_positive_class_percentage:.2f}%\")\n",
    "\n",
    "            # Compute class weights\n",
    "            class_weights = compute_class_weight('balanced', classes=np.unique(y_train_binary), y=y_train_binary)\n",
    "            class_weights = torch.FloatTensor(class_weights).to(device)\n",
    "            logger.info(f\"Class weights: {class_weights}\")\n",
    "\n",
    "            train_dataset = TensorDataset(X_train_tensor, torch.FloatTensor(y_train_binary).to(device))\n",
    "            train_loader = DataLoader(train_dataset, batch_size=params['BATCH_SIZE'], shuffle=True)\n",
    "\n",
    "            # Initialize model\n",
    "            model = StockAnalysisModel(\n",
    "                input_size=X_train.shape[2],\n",
    "                lstm_layers=params['LSTM_LAYERS'],\n",
    "                linear_layers=params['LINEAR_LAYERS'],\n",
    "                dropout_rate_lstm=params['DROPOUT_RATE_LSTM'],\n",
    "                dropout_rate_linear=params['DROPOUT_RATE_LINEAR'],\n",
    "                skip_connections=params['SKIP_CONNECTIONS']\n",
    "            ).to(device)\n",
    "            logger.info(f\"Model architecture: {model}\")\n",
    "\n",
    "            # Define loss function and optimizer\n",
    "            criterion = nn.BCELoss(reduction='none')\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=params['LEARNING_RATE'], weight_decay=params['L2_REGULARIZATION'])\n",
    "\n",
    "            # Directory to save checkpoints\n",
    "            checkpoint_dir = './checkpoints'\n",
    "            os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, 'model_checkpoint.pth')\n",
    "            start_epoch = 0\n",
    "            best_f1 = 0\n",
    "            best_model = copy.deepcopy(model)\n",
    "            previous_params = None\n",
    "            patience = 10\n",
    "            no_improvement_count = 0\n",
    "\n",
    "            # Load checkpoint if exists\n",
    "            if os.path.exists(checkpoint_path):\n",
    "                try:\n",
    "                    start_epoch, best_f1, previous_params = load_checkpoint(checkpoint_path, model, optimizer)\n",
    "                    logger.info(f\"Resuming training from epoch {start_epoch} with best F1 score {best_f1:.4f}\")\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"Could not load checkpoint: {e}. Starting from scratch.\")\n",
    "\n",
    "            # Ensure model architecture matches\n",
    "            if previous_params and params != previous_params:\n",
    "                logger.info(f\"Model architecture changed, not loading from checkpoint. Previous params: {previous_params}, Current params: {params}\")\n",
    "                start_epoch = 0\n",
    "                best_f1 = 0\n",
    "\n",
    "            # Training loop\n",
    "            n_epochs = 50\n",
    "            for epoch in range(start_epoch, n_epochs):\n",
    "                model.train()\n",
    "                total_loss = 0\n",
    "                all_train_preds = []\n",
    "                all_train_labels = []\n",
    "                for batch_X, batch_y in train_loader:\n",
    "                    optimizer.zero_grad()\n",
    "                    try:\n",
    "                        outputs = model(batch_X)\n",
    "                        # Apply class weights manually\n",
    "                        weights = class_weights[batch_y.long()]\n",
    "                        losses = criterion(outputs, batch_y)\n",
    "                        weighted_losses = losses * weights\n",
    "                        loss = weighted_losses.mean()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        total_loss += loss.item()\n",
    "\n",
    "                        all_train_preds.extend(outputs.detach().cpu().numpy())\n",
    "                        all_train_labels.extend(batch_y.cpu().numpy())\n",
    "                    except RuntimeError as e:\n",
    "                        if \"out of memory\" in str(e):\n",
    "                            logger.error(f\"CUDA out of memory error: {str(e)}\")\n",
    "                            return float('inf')  # Indicate failure to Optuna\n",
    "                        else:\n",
    "                            raise e\n",
    "            \n",
    "                # Calculate training metrics\n",
    "                train_preds_binary = (np.array(all_train_preds) > params['PREDICTION_THRESHOLD']).astype(int)\n",
    "                train_precision = precision_score(all_train_labels, train_preds_binary, zero_division=0)\n",
    "                train_recall = recall_score(all_train_labels, train_preds_binary, zero_division=0)\n",
    "                train_f1 = f1_score(all_train_labels, train_preds_binary, zero_division=0)\n",
    "\n",
    "                # Validation\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    y_pred = model(X_test_tensor)\n",
    "                    y_pred_binary = (y_pred > params['PREDICTION_THRESHOLD']).float()\n",
    "\n",
    "                    # Calculate metrics\n",
    "                    precision = precision_score(y_test_binary, y_pred_binary.cpu().numpy(), zero_division=0)\n",
    "                    recall = recall_score(y_test_binary, y_pred_binary.cpu().numpy(), zero_division=0)\n",
    "                    f1 = f1_score(y_test_binary, y_pred_binary.cpu().numpy(), zero_division=0)\n",
    "\n",
    "                    logger.info(f\"Epoch {epoch}: Loss: {total_loss/len(train_loader):.4f}\")\n",
    "                    logger.info(f\"Train - Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, F1: {train_f1:.4f}\")\n",
    "                    logger.info(f\"Val - Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
    "\n",
    "                    if f1 > best_f1:\n",
    "                        best_f1 = f1\n",
    "                        best_model = copy.deepcopy(model)\n",
    "                        no_improvement_count = 0  # Reset the no improvement count\n",
    "                    else:\n",
    "                        no_improvement_count += 1\n",
    "\n",
    "                # Save checkpoint\n",
    "                save_checkpoint(epoch + 1, model, optimizer, best_f1, params, checkpoint_path)\n",
    "\n",
    "                # Log metrics\n",
    "                mlflow.log_metric(\"train_loss\", total_loss / len(train_loader), step=epoch)\n",
    "                mlflow.log_metric(\"train_precision\", train_precision, step=epoch)\n",
    "                mlflow.log_metric(\"train_recall\", train_recall, step=epoch)\n",
    "                mlflow.log_metric(\"train_f1\", train_f1, step=epoch)\n",
    "                mlflow.log_metric(\"val_precision\", precision, step=epoch)\n",
    "                mlflow.log_metric(\"val_recall\", recall, step=epoch)\n",
    "                mlflow.log_metric(\"val_f1\", f1, step=epoch)\n",
    "\n",
    "                # Early stopping\n",
    "                if no_improvement_count >= patience:\n",
    "                    logger.info(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
    "                    break\n",
    "\n",
    "            # Final evaluation\n",
    "            best_model.eval()\n",
    "            with torch.no_grad():\n",
    "                y_pred = best_model(X_test_tensor)\n",
    "                y_pred_binary = (y_pred > params['PREDICTION_THRESHOLD']).float()\n",
    "\n",
    "                precision = precision_score(y_test_binary, y_pred_binary.cpu().numpy(), zero_division=0)\n",
    "                recall = recall_score(y_test_binary, y_pred_binary.cpu().numpy(), zero_division=0)\n",
    "                f1 = f1_score(y_test_binary, y_pred_binary.cpu().numpy(), zero_division=0)\n",
    "                conf_matrix = confusion_matrix(y_test_binary, y_pred_binary.cpu().numpy())\n",
    "\n",
    "                # Calculate the percentage of positive predictions\n",
    "                positive_pred_percentage = y_pred_binary.mean().item() * 100\n",
    "\n",
    "                # Log final metrics\n",
    "                mlflow.log_metric(\"test_precision\", precision)\n",
    "                mlflow.log_metric(\"test_recall\", recall)\n",
    "                mlflow.log_metric(\"test_f1\", f1)\n",
    "                mlflow.log_metric(\"positive_pred_percentage\", positive_pred_percentage)\n",
    "\n",
    "                logger.info(f\"Test Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
    "                logger.info(f\"Positive prediction percentage: {positive_pred_percentage:.2f}%\")\n",
    "                logger.info(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "\n",
    "                # Log confusion matrix as a figure\n",
    "                plt.figure(figsize=(10,8))\n",
    "                sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "                plt.title('Confusion Matrix')\n",
    "                plt.ylabel('True label')\n",
    "                plt.xlabel('Predicted label')\n",
    "                plt.savefig(\"confusion_matrix.png\")\n",
    "                mlflow.log_artifact(\"confusion_matrix.png\")\n",
    "\n",
    "                # Log the PyTorch model\n",
    "                mlflow.pytorch.log_model(best_model, \"model\")\n",
    "\n",
    "            # Penalize if the model is just predicting the majority class\n",
    "            if positive_pred_percentage < 0.1 or positive_pred_percentage > 99.9:\n",
    "                f1 = 0\n",
    "\n",
    "            logger.info(f\"Trial completed. Best F1 score: {f1:.4f}\")\n",
    "            return f1\n",
    "    \n",
    "    except torch.cuda.OutOfMemoryError as e:\n",
    "        logger.error(f\"CUDA out of memory error: {str(e)}\")\n",
    "        return float('inf')  # Indicate failure to Optuna\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unexpected error: {str(e)}\")\n",
    "        return float('inf')  # Indicate failure to Optuna\n",
    "\n",
    "    \n",
    "# Run Optuna optimization\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Print and log the best parameters and score\n",
    "best_params = study.best_params\n",
    "best_score = study.best_value\n",
    "logger.info(f\"Best parameters: {best_params}\")\n",
    "logger.info(f\"Best precision score: {best_score}\")\n",
    "\n",
    "# Save the best parameters to a JSON file\n",
    "with open('best_params.json', 'w') as f:\n",
    "    json.dump(best_params, f)\n",
    "\n",
    "logger.info(\"Hyperparameter tuning completed. Best parameters saved to 'best_params.json'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
